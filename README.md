# Benchmarking Supervised ML Models for Sentiment Classification (NLP) on IMDB Movie Reviews ðŸŽ¬

This project focuses on building and evaluating machine learning models for sentiment classification of IMDB movie reviews (positive vs. negative). The workflow follows a structured and modular pipeline for preprocessing, feature extraction, model training, evaluation, selection, and error analysis.

---

## ðŸ“‚ Dataset

- **Source:** [Kaggle â€“ IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)  
- **Columns:** `review`, `sentiment`  
---

## ðŸ§° Project Structure
```
Benchmarking-Supervised-ML-Models-for-Sentiment-Classification-NLP-on-IMDB-Reviews/
â”‚
â”œâ”€â”€ data/ # Raw and processed CSV datasets
â”œâ”€â”€ notebooks/ #(Colab)-IMDB_Movie_Reviews_Sentiment_Analysis.ipynb
â”œâ”€â”€ results/
| â”œâ”€â”€ Text files of all False-positives and false-negative/ #(.txt files of all False-Positives and False-Negatives)
| â””â”€â”€ error_analysis.md 
â”œâ”€â”€ src/ # All modular functions
| â”œâ”€â”€ __init__.py
| â”œâ”€â”€ data_loading.py
â”‚ â”œâ”€â”€ data_preprocessing.py
â”‚ â”œâ”€â”€ error_analysis.py
â”‚ â”œâ”€â”€ feature_extraction.py
| â”œâ”€â”€ hyperparameter_tuning.py
| â”œâ”€â”€ model_evaluation.py
| â”œâ”€â”€ model_performance_comparison.py
| â”œâ”€â”€ model_training.py
| â”œâ”€â”€ reporting.py
â”‚ â”œâ”€â”€ select_best_models.py
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
---

## ðŸ”¹ Workflow

1. **Data Loading & Preprocessing**  
   - Text cleaning, tokenization, stopword removal, stemming, and label binarization.  
   - Convert raw reviews into usable text format.

2. **Feature Extraction**  
   - Bag-of-Words (BoW)  
   - Term Frequency-Inverse Document Frequency (TF-IDF)

3. **Model Training, Hypertuning & Evaluation**  
   - Models: Logistic Regression, MultinomialNB, SGDClassifier, LinearSVC  
   - Configurations: Baseline & Tuned  
   - Metrics: Accuracy, Precision, Recall, F1-Score  

4. **Visualization**  
   - Confusion matrices  
   - Barplots for model performance comparisons

5. **Best Model Selection**  
   - Identify the **best (BoW) baseline** and **best (tf-idf)tuned model** based on **F1-Score**.
     
6. **Error Analysis**  
   - Compute **False Positives (FP)** and **False Negatives (FN)** for both models.
   - [Generate detailed `.txt` files for FP & FN instances:](https://github.com/TuliDas/Benchmarking-Supervised-ML-Models-for-Sentiment-Classification-NLP-on-IMDB-Reviews/tree/main/results/Text%20files%20of%20all%20False-positives%20and%20false-negative)
     - Detected by both models
     - Detected by baseline only
     - Detected by tuned only  
   - [Compare misclassifications between baseline-BoW and tuned-Tf-Idf models.](https://github.com/TuliDas/Benchmarking-Supervised-ML-Models-for-Sentiment-Classification-NLP-on-IMDB-Reviews/blob/main/results/error_analysis.md)  

---

## How to Run

### Using Google Colab
1. Open the notebook: [`IMDB_Movie_Reviews_Sentiment_Analysis.ipynb`](notebooks/IMDB_Movie_Reviews_Sentiment_Analysis.ipynb)  
2. Run all cells **sequentially**.  
3. The first cell contains a `git clone` command that will automatically download all the `src/` modules into the Colab environment.  
4. Outputs, including model performance metrics, error analysis files, and visualizations, will be generated in Colab.  
---
