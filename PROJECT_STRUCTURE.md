
## ðŸ§° Project Structure
```
Benchmark-ML-Models-Movie-Reviews-Sentiment/
â”‚
â”œâ”€â”€ data/ 
|   â””â”€â”€ dataset_link.md                    
â”‚
â”œâ”€â”€ notebooks/
â”‚    â”œâ”€â”€ main.ipynb (#Colab)
â”‚    â””â”€â”€ IMDB_Movie_Reviews_Sentiment_Analysis.ipynb (with outputs)                  
â”‚
â”œâ”€â”€ src/  # All modular functions                  
|   â”œâ”€â”€ __init__.py
|   â”œâ”€â”€ data_loading.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ error_analysis.py
â”‚   â”œâ”€â”€ feature_extraction.py
|   â”œâ”€â”€ hyperparameter_tuning.py
|   â”œâ”€â”€ model_evaluation.py
|   â”œâ”€â”€ model_performance_comparison.py
|   â”œâ”€â”€ model_training.py
|   â”œâ”€â”€ reporting.py
â”‚   â”œâ”€â”€ select_best_models.py
â”‚   â””â”€â”€ utils.py
â”‚ 
â”œâ”€â”€ results/                  # All evaluation outputs
â”‚   â”œâ”€â”€ metrics/              # Numeric/tabular results
â”‚   â”‚   â”œâ”€â”€ classification_metrics.md
â”‚   â”‚   â”œâ”€â”€ metrics_summary.json
â”‚   â”‚   â”œâ”€â”€ confusion_metrics_scores.md
â”‚   â”‚   â”œâ”€â”€ ConfisionMatrix-LinearSVC-tuned-BoW.png
â”‚   â”‚   â””â”€â”€ ConfisionMatrix-LR-baseline-BoW.png
â”‚   â”‚
â”‚   â”œâ”€â”€ reports/              # Human-readable analysis
â”‚   â”‚   â”œâ”€â”€ error_analysis.md
â”‚   â”‚   â””â”€â”€ discussion.md
â”‚   â”‚
â”‚   â”œâ”€â”€ fp_fn_lists/          # Plain text lists of misclassifications
â”‚   â”‚   â”œâ”€â”€ Both-Models' Predicted FP & FN list.txt
â”‚   â”‚   â”œâ”€â”€ Only-LogisticRegression-Baseline-(BoW)-FP & FN lists.txt
â”‚   â”‚   â”œâ”€â”€ Only-LinearSVC-Tuned-(TF-IDF)-FP & FN lists.txt
â”‚   â”‚   â”œâ”€â”€ fp-fn-of-best-two-models.png
â”‚   â”‚   â””â”€â”€ fp-fn-overlaping.png
â”‚   â”‚
â”‚   â””â”€â”€ figures/              
â”‚       â””â”€â”€ baseline-vs-tuned-accuracy-comparison.png
â”‚
â””â”€â”€ README.md
```